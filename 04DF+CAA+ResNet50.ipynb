{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T06:06:22.959696900Z",
     "start_time": "2024-11-11T06:06:22.946942500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50\n",
    "from typing import Optional\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# 超参数\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pic_size=224\n",
    "# 数据预处理和加载\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),  # 随机擦除\n",
    "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),  # 颜色抖动\n",
    "    transforms.Resize([pic_size,pic_size],antialias=False),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# 加载训练和验证数据集\n",
    "train_dataset = datasets.ImageFolder(root='MyGTData/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='MyGTData/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,pin_memory=True,num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True,pin_memory=True,num_workers=0)\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "from DF import DilateAttention,MultiDilatelocalAttention\n",
    "from CAA import CAA,ConvModule\n",
    "from LossFunction import FocalLoss,LabelSmoothingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T06:06:23.861134500Z",
     "start_time": "2024-11-11T06:06:23.859128300Z"
    }
   },
   "id": "b7d94de46f74bdcd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from torchvision.models import wide_resnet50_2\n",
    "class ResNetWithDilateAttention(nn.Module):\n",
    "    def __init__(self,channels,pic_size,nc):\n",
    "        super(ResNetWithDilateAttention, self).__init__()\n",
    "        # 使用ResNet50的预训练模型\n",
    "        self.mdla=MultiDilatelocalAttention(dim=pic_size).cuda()\n",
    "        self.caa=CAA(channels=channels).cuda()\n",
    "        self.resnet = resnet50(weights=None,num_classes=nc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.mdla(x)     \n",
    "        x=self.caa(x)\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型、定义损失函数和优化器\n",
    "model = ResNetWithDilateAttention(channels=3,pic_size=pic_size,nc=4)\n",
    "model.to(device)\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "focal_loss = FocalLoss(alpha=1, gamma=2)\n",
    "label_smoothing_loss = LabelSmoothingLoss(classes=4, smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T06:06:25.131120400Z",
     "start_time": "2024-11-11T06:06:24.603138800Z"
    }
   },
   "id": "1f40a9d6617b6056"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Batch 0, Total Loss: 5.6668, Cross Entropy Loss: 2.0706, Focal Loss: 1.5845, Label Smoothing Loss: 2.0118\n",
      "Epoch 2/100, Batch 0, Total Loss: 3.0224, Cross Entropy Loss: 0.8488, Focal Loss: 0.8224, Label Smoothing Loss: 1.3512\n",
      "Epoch 3/100, Batch 0, Total Loss: 1.2925, Cross Entropy Loss: 0.3772, Focal Loss: 0.1268, Label Smoothing Loss: 0.7885\n",
      "Epoch 4/100, Batch 0, Total Loss: 1.2565, Cross Entropy Loss: 0.3291, Focal Loss: 0.1720, Label Smoothing Loss: 0.7554\n",
      "Epoch 5/100, Batch 0, Total Loss: 0.8780, Cross Entropy Loss: 0.1923, Focal Loss: 0.0665, Label Smoothing Loss: 0.6193\n",
      "Epoch 6/100, Batch 0, Total Loss: 0.8670, Cross Entropy Loss: 0.2476, Focal Loss: 0.0356, Label Smoothing Loss: 0.5838\n",
      "Epoch 7/100, Batch 0, Total Loss: 0.8780, Cross Entropy Loss: 0.1976, Focal Loss: 0.0859, Label Smoothing Loss: 0.5945\n",
      "Epoch 8/100, Batch 0, Total Loss: 0.7634, Cross Entropy Loss: 0.2080, Focal Loss: 0.0492, Label Smoothing Loss: 0.5062\n",
      "Epoch 9/100, Batch 0, Total Loss: 0.8525, Cross Entropy Loss: 0.2702, Focal Loss: 0.0480, Label Smoothing Loss: 0.5343\n",
      "Epoch 10/100, Batch 0, Total Loss: 0.9606, Cross Entropy Loss: 0.2839, Focal Loss: 0.1312, Label Smoothing Loss: 0.5455\n",
      "Test Accuracy: 69.64%\n",
      "F1 Score: 0.56\n",
      "ROC-AUC: 0.27\n",
      "Epoch 11/100, Batch 0, Total Loss: 0.7392, Cross Entropy Loss: 0.2168, Focal Loss: 0.0335, Label Smoothing Loss: 0.4889\n",
      "Epoch 12/100, Batch 0, Total Loss: 0.6012, Cross Entropy Loss: 0.1340, Focal Loss: 0.0235, Label Smoothing Loss: 0.4437\n",
      "Epoch 13/100, Batch 0, Total Loss: 0.5234, Cross Entropy Loss: 0.0952, Focal Loss: 0.0047, Label Smoothing Loss: 0.4235\n",
      "Epoch 14/100, Batch 0, Total Loss: 0.7038, Cross Entropy Loss: 0.1587, Focal Loss: 0.0319, Label Smoothing Loss: 0.5132\n",
      "Epoch 15/100, Batch 0, Total Loss: 0.6334, Cross Entropy Loss: 0.1345, Focal Loss: 0.0279, Label Smoothing Loss: 0.4709\n",
      "Epoch 16/100, Batch 0, Total Loss: 0.6867, Cross Entropy Loss: 0.1275, Focal Loss: 0.0459, Label Smoothing Loss: 0.5133\n",
      "Epoch 17/100, Batch 0, Total Loss: 0.9881, Cross Entropy Loss: 0.2548, Focal Loss: 0.1626, Label Smoothing Loss: 0.5707\n",
      "Epoch 18/100, Batch 0, Total Loss: 0.7053, Cross Entropy Loss: 0.1880, Focal Loss: 0.0397, Label Smoothing Loss: 0.4776\n",
      "Epoch 19/100, Batch 0, Total Loss: 0.7188, Cross Entropy Loss: 0.1428, Focal Loss: 0.0723, Label Smoothing Loss: 0.5037\n",
      "Epoch 20/100, Batch 0, Total Loss: 0.8613, Cross Entropy Loss: 0.2179, Focal Loss: 0.0950, Label Smoothing Loss: 0.5483\n",
      "Test Accuracy: 67.86%\n",
      "F1 Score: 0.55\n",
      "ROC-AUC: 0.20\n",
      "Epoch 21/100, Batch 0, Total Loss: 0.7110, Cross Entropy Loss: 0.1460, Focal Loss: 0.0562, Label Smoothing Loss: 0.5089\n",
      "Epoch 22/100, Batch 0, Total Loss: 0.6559, Cross Entropy Loss: 0.1376, Focal Loss: 0.0367, Label Smoothing Loss: 0.4816\n",
      "Epoch 23/100, Batch 0, Total Loss: 0.7131, Cross Entropy Loss: 0.1797, Focal Loss: 0.0487, Label Smoothing Loss: 0.4847\n",
      "Epoch 24/100, Batch 0, Total Loss: 0.4708, Cross Entropy Loss: 0.0550, Focal Loss: 0.0031, Label Smoothing Loss: 0.4127\n",
      "Epoch 25/100, Batch 0, Total Loss: 0.4724, Cross Entropy Loss: 0.0712, Focal Loss: 0.0024, Label Smoothing Loss: 0.3988\n",
      "Epoch 26/100, Batch 0, Total Loss: 0.9241, Cross Entropy Loss: 0.2203, Focal Loss: 0.1461, Label Smoothing Loss: 0.5578\n",
      "Epoch 27/100, Batch 0, Total Loss: 0.7224, Cross Entropy Loss: 0.1732, Focal Loss: 0.0606, Label Smoothing Loss: 0.4886\n",
      "Epoch 28/100, Batch 0, Total Loss: 0.4407, Cross Entropy Loss: 0.0407, Focal Loss: 0.0006, Label Smoothing Loss: 0.3993\n",
      "Epoch 29/100, Batch 0, Total Loss: 0.4407, Cross Entropy Loss: 0.0476, Focal Loss: 0.0006, Label Smoothing Loss: 0.3925\n",
      "Epoch 30/100, Batch 0, Total Loss: 0.4324, Cross Entropy Loss: 0.0492, Focal Loss: 0.0005, Label Smoothing Loss: 0.3828\n",
      "Test Accuracy: 76.79%\n",
      "F1 Score: 0.72\n",
      "ROC-AUC: 0.11\n",
      "Epoch 31/100, Batch 0, Total Loss: 0.4582, Cross Entropy Loss: 0.0834, Focal Loss: 0.0014, Label Smoothing Loss: 0.3735\n",
      "Epoch 32/100, Batch 0, Total Loss: 0.4582, Cross Entropy Loss: 0.0572, Focal Loss: 0.0016, Label Smoothing Loss: 0.3995\n",
      "Epoch 33/100, Batch 0, Total Loss: 0.4367, Cross Entropy Loss: 0.0333, Focal Loss: 0.0002, Label Smoothing Loss: 0.4032\n",
      "Epoch 34/100, Batch 0, Total Loss: 0.4365, Cross Entropy Loss: 0.0491, Focal Loss: 0.0005, Label Smoothing Loss: 0.3869\n",
      "Epoch 35/100, Batch 0, Total Loss: 0.4998, Cross Entropy Loss: 0.0774, Focal Loss: 0.0082, Label Smoothing Loss: 0.4142\n",
      "Epoch 36/100, Batch 0, Total Loss: 0.4860, Cross Entropy Loss: 0.0611, Focal Loss: 0.0030, Label Smoothing Loss: 0.4219\n",
      "Epoch 37/100, Batch 0, Total Loss: 0.9560, Cross Entropy Loss: 0.2329, Focal Loss: 0.1465, Label Smoothing Loss: 0.5766\n",
      "Epoch 38/100, Batch 0, Total Loss: 0.4279, Cross Entropy Loss: 0.0403, Focal Loss: 0.0004, Label Smoothing Loss: 0.3872\n",
      "Epoch 39/100, Batch 0, Total Loss: 0.4156, Cross Entropy Loss: 0.0383, Focal Loss: 0.0001, Label Smoothing Loss: 0.3771\n",
      "Epoch 40/100, Batch 0, Total Loss: 0.4608, Cross Entropy Loss: 0.0601, Focal Loss: 0.0016, Label Smoothing Loss: 0.3992\n",
      "Test Accuracy: 76.79%\n",
      "F1 Score: 0.71\n",
      "ROC-AUC: 0.13\n",
      "Epoch 41/100, Batch 0, Total Loss: 0.4269, Cross Entropy Loss: 0.0416, Focal Loss: 0.0002, Label Smoothing Loss: 0.3851\n",
      "Epoch 42/100, Batch 0, Total Loss: 0.4348, Cross Entropy Loss: 0.0517, Focal Loss: 0.0006, Label Smoothing Loss: 0.3825\n",
      "Epoch 43/100, Batch 0, Total Loss: 0.4243, Cross Entropy Loss: 0.0542, Focal Loss: 0.0003, Label Smoothing Loss: 0.3698\n",
      "Epoch 44/100, Batch 0, Total Loss: 0.4177, Cross Entropy Loss: 0.0349, Focal Loss: 0.0001, Label Smoothing Loss: 0.3827\n",
      "Epoch 45/100, Batch 0, Total Loss: 0.4181, Cross Entropy Loss: 0.0356, Focal Loss: 0.0001, Label Smoothing Loss: 0.3824\n",
      "Epoch 46/100, Batch 0, Total Loss: 0.4544, Cross Entropy Loss: 0.0491, Focal Loss: 0.0022, Label Smoothing Loss: 0.4031\n",
      "Epoch 47/100, Batch 0, Total Loss: 0.4260, Cross Entropy Loss: 0.0634, Focal Loss: 0.0004, Label Smoothing Loss: 0.3621\n",
      "Epoch 48/100, Batch 0, Total Loss: 0.4219, Cross Entropy Loss: 0.0188, Focal Loss: 0.0000, Label Smoothing Loss: 0.4031\n",
      "Epoch 49/100, Batch 0, Total Loss: 0.4117, Cross Entropy Loss: 0.0430, Focal Loss: 0.0001, Label Smoothing Loss: 0.3686\n",
      "Epoch 50/100, Batch 0, Total Loss: 0.4218, Cross Entropy Loss: 0.0351, Focal Loss: 0.0002, Label Smoothing Loss: 0.3866\n",
      "Test Accuracy: 83.93%\n",
      "F1 Score: 0.81\n",
      "ROC-AUC: 0.13\n",
      "Epoch 51/100, Batch 0, Total Loss: 0.4160, Cross Entropy Loss: 0.0507, Focal Loss: 0.0002, Label Smoothing Loss: 0.3652\n",
      "Epoch 52/100, Batch 0, Total Loss: 0.4090, Cross Entropy Loss: 0.0310, Focal Loss: 0.0001, Label Smoothing Loss: 0.3779\n",
      "Epoch 53/100, Batch 0, Total Loss: 0.4088, Cross Entropy Loss: 0.0392, Focal Loss: 0.0001, Label Smoothing Loss: 0.3696\n",
      "Epoch 54/100, Batch 0, Total Loss: 0.4045, Cross Entropy Loss: 0.0378, Focal Loss: 0.0001, Label Smoothing Loss: 0.3667\n",
      "Epoch 55/100, Batch 0, Total Loss: 0.4136, Cross Entropy Loss: 0.0342, Focal Loss: 0.0001, Label Smoothing Loss: 0.3793\n",
      "Epoch 56/100, Batch 0, Total Loss: 0.4042, Cross Entropy Loss: 0.0366, Focal Loss: 0.0001, Label Smoothing Loss: 0.3675\n",
      "Epoch 57/100, Batch 0, Total Loss: 0.4069, Cross Entropy Loss: 0.0349, Focal Loss: 0.0000, Label Smoothing Loss: 0.3720\n",
      "Epoch 58/100, Batch 0, Total Loss: 0.4069, Cross Entropy Loss: 0.0394, Focal Loss: 0.0001, Label Smoothing Loss: 0.3674\n",
      "Epoch 59/100, Batch 0, Total Loss: 0.4065, Cross Entropy Loss: 0.0370, Focal Loss: 0.0001, Label Smoothing Loss: 0.3695\n",
      "Epoch 60/100, Batch 0, Total Loss: 0.4049, Cross Entropy Loss: 0.0332, Focal Loss: 0.0000, Label Smoothing Loss: 0.3717\n",
      "Test Accuracy: 91.07%\n",
      "F1 Score: 0.90\n",
      "ROC-AUC: 0.15\n",
      "Epoch 61/100, Batch 0, Total Loss: 0.4038, Cross Entropy Loss: 0.0359, Focal Loss: 0.0000, Label Smoothing Loss: 0.3679\n",
      "Epoch 62/100, Batch 0, Total Loss: 0.4041, Cross Entropy Loss: 0.0334, Focal Loss: 0.0000, Label Smoothing Loss: 0.3707\n",
      "Epoch 63/100, Batch 0, Total Loss: 0.4037, Cross Entropy Loss: 0.0369, Focal Loss: 0.0001, Label Smoothing Loss: 0.3667\n",
      "Epoch 64/100, Batch 0, Total Loss: 0.4032, Cross Entropy Loss: 0.0352, Focal Loss: 0.0000, Label Smoothing Loss: 0.3679\n",
      "Epoch 65/100, Batch 0, Total Loss: 0.4039, Cross Entropy Loss: 0.0375, Focal Loss: 0.0001, Label Smoothing Loss: 0.3664\n",
      "Epoch 66/100, Batch 0, Total Loss: 0.4046, Cross Entropy Loss: 0.0329, Focal Loss: 0.0000, Label Smoothing Loss: 0.3717\n",
      "Epoch 67/100, Batch 0, Total Loss: 0.4031, Cross Entropy Loss: 0.0373, Focal Loss: 0.0001, Label Smoothing Loss: 0.3657\n",
      "Epoch 68/100, Batch 0, Total Loss: 0.4123, Cross Entropy Loss: 0.0352, Focal Loss: 0.0001, Label Smoothing Loss: 0.3771\n",
      "Epoch 69/100, Batch 0, Total Loss: 0.4103, Cross Entropy Loss: 0.0297, Focal Loss: 0.0000, Label Smoothing Loss: 0.3805\n",
      "Epoch 70/100, Batch 0, Total Loss: 0.4048, Cross Entropy Loss: 0.0364, Focal Loss: 0.0001, Label Smoothing Loss: 0.3683\n",
      "Test Accuracy: 83.93%\n",
      "F1 Score: 0.81\n",
      "ROC-AUC: 0.12\n",
      "Epoch 71/100, Batch 0, Total Loss: 0.4030, Cross Entropy Loss: 0.0362, Focal Loss: 0.0000, Label Smoothing Loss: 0.3668\n",
      "Epoch 72/100, Batch 0, Total Loss: 0.4044, Cross Entropy Loss: 0.0306, Focal Loss: 0.0000, Label Smoothing Loss: 0.3737\n",
      "Epoch 73/100, Batch 0, Total Loss: 0.4058, Cross Entropy Loss: 0.0310, Focal Loss: 0.0000, Label Smoothing Loss: 0.3747\n",
      "Epoch 74/100, Batch 0, Total Loss: 0.4034, Cross Entropy Loss: 0.0406, Focal Loss: 0.0001, Label Smoothing Loss: 0.3627\n",
      "Epoch 75/100, Batch 0, Total Loss: 0.4038, Cross Entropy Loss: 0.0342, Focal Loss: 0.0000, Label Smoothing Loss: 0.3696\n",
      "Epoch 76/100, Batch 0, Total Loss: 0.4080, Cross Entropy Loss: 0.0383, Focal Loss: 0.0001, Label Smoothing Loss: 0.3697\n",
      "Epoch 77/100, Batch 0, Total Loss: 0.4115, Cross Entropy Loss: 0.0476, Focal Loss: 0.0001, Label Smoothing Loss: 0.3638\n",
      "Epoch 78/100, Batch 0, Total Loss: 0.4098, Cross Entropy Loss: 0.0324, Focal Loss: 0.0001, Label Smoothing Loss: 0.3774\n",
      "Epoch 79/100, Batch 0, Total Loss: 0.4046, Cross Entropy Loss: 0.0360, Focal Loss: 0.0001, Label Smoothing Loss: 0.3685\n",
      "Epoch 80/100, Batch 0, Total Loss: 0.4037, Cross Entropy Loss: 0.0392, Focal Loss: 0.0001, Label Smoothing Loss: 0.3645\n",
      "Test Accuracy: 87.50%\n",
      "F1 Score: 0.86\n",
      "ROC-AUC: 0.14\n",
      "Epoch 81/100, Batch 0, Total Loss: 0.4045, Cross Entropy Loss: 0.0365, Focal Loss: 0.0001, Label Smoothing Loss: 0.3680\n",
      "Epoch 82/100, Batch 0, Total Loss: 0.4030, Cross Entropy Loss: 0.0376, Focal Loss: 0.0001, Label Smoothing Loss: 0.3653\n",
      "Epoch 83/100, Batch 0, Total Loss: 0.4037, Cross Entropy Loss: 0.0381, Focal Loss: 0.0001, Label Smoothing Loss: 0.3656\n",
      "Epoch 84/100, Batch 0, Total Loss: 0.4057, Cross Entropy Loss: 0.0359, Focal Loss: 0.0000, Label Smoothing Loss: 0.3697\n",
      "Epoch 85/100, Batch 0, Total Loss: 0.4045, Cross Entropy Loss: 0.0357, Focal Loss: 0.0000, Label Smoothing Loss: 0.3688\n",
      "Epoch 86/100, Batch 0, Total Loss: 0.4081, Cross Entropy Loss: 0.0478, Focal Loss: 0.0001, Label Smoothing Loss: 0.3602\n",
      "Epoch 87/100, Batch 0, Total Loss: 0.4253, Cross Entropy Loss: 0.0708, Focal Loss: 0.0004, Label Smoothing Loss: 0.3541\n",
      "Epoch 88/100, Batch 0, Total Loss: 0.4062, Cross Entropy Loss: 0.0298, Focal Loss: 0.0000, Label Smoothing Loss: 0.3763\n",
      "Epoch 89/100, Batch 0, Total Loss: 0.4050, Cross Entropy Loss: 0.0320, Focal Loss: 0.0000, Label Smoothing Loss: 0.3730\n",
      "Epoch 90/100, Batch 0, Total Loss: 0.4067, Cross Entropy Loss: 0.0469, Focal Loss: 0.0001, Label Smoothing Loss: 0.3597\n",
      "Test Accuracy: 82.14%\n",
      "F1 Score: 0.79\n",
      "ROC-AUC: 0.13\n",
      "Epoch 91/100, Batch 0, Total Loss: 0.4042, Cross Entropy Loss: 0.0407, Focal Loss: 0.0001, Label Smoothing Loss: 0.3634\n",
      "Epoch 92/100, Batch 0, Total Loss: 0.4079, Cross Entropy Loss: 0.0471, Focal Loss: 0.0001, Label Smoothing Loss: 0.3607\n",
      "Epoch 93/100, Batch 0, Total Loss: 0.4033, Cross Entropy Loss: 0.0351, Focal Loss: 0.0000, Label Smoothing Loss: 0.3682\n",
      "Epoch 94/100, Batch 0, Total Loss: 0.4041, Cross Entropy Loss: 0.0355, Focal Loss: 0.0000, Label Smoothing Loss: 0.3685\n",
      "Epoch 95/100, Batch 0, Total Loss: 0.4038, Cross Entropy Loss: 0.0372, Focal Loss: 0.0001, Label Smoothing Loss: 0.3665\n",
      "Epoch 96/100, Batch 0, Total Loss: 0.4093, Cross Entropy Loss: 0.0355, Focal Loss: 0.0001, Label Smoothing Loss: 0.3738\n",
      "Epoch 97/100, Batch 0, Total Loss: 0.4039, Cross Entropy Loss: 0.0341, Focal Loss: 0.0000, Label Smoothing Loss: 0.3698\n",
      "Epoch 98/100, Batch 0, Total Loss: 0.4041, Cross Entropy Loss: 0.0403, Focal Loss: 0.0001, Label Smoothing Loss: 0.3637\n",
      "Epoch 99/100, Batch 0, Total Loss: 0.4037, Cross Entropy Loss: 0.0341, Focal Loss: 0.0000, Label Smoothing Loss: 0.3696\n",
      "Epoch 100/100, Batch 0, Total Loss: 0.4086, Cross Entropy Loss: 0.0270, Focal Loss: 0.0000, Label Smoothing Loss: 0.3816\n",
      "Test Accuracy: 91.07%\n",
      "F1 Score: 0.90\n",
      "ROC-AUC: 0.18\n",
      "Total training time: 3194.80 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 配置日志记录\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# 记录训练开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        # 计算损失\n",
    "        ce_loss = cross_entropy_loss(output, target)\n",
    "        focal = focal_loss(output, target)\n",
    "        ls_loss = label_smoothing_loss(output, target)\n",
    "        loss = ce_loss + focal + ls_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 每隔100个batch打印并记录日志\n",
    "        if batch_idx % 100 == 0:\n",
    "            log_message = f'Epoch {epoch}/{num_epochs}, Batch {batch_idx}, Total Loss: {loss.item():.4f}, Cross Entropy Loss: {ce_loss.item():.4f}, Focal Loss: {focal.item():.4f}, Label Smoothing Loss: {ls_loss.item():.4f}'\n",
    "            print(log_message)\n",
    "            logging.info(log_message)\n",
    "\n",
    "    # 每隔10个epoch进行测试并记录\n",
    "    if epoch % 10 == 0:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "                # 保存预测结果\n",
    "                all_preds.extend(probabilities.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "        # 计算准确率\n",
    "        accuracy = 100 * correct / total\n",
    "        log_message = f'Test Accuracy: {accuracy:.2f}%'\n",
    "        print(log_message)\n",
    "        logging.info(log_message)\n",
    "\n",
    "        # 计算F1分数\n",
    "        f1 = f1_score(all_targets, np.argmax(all_preds, axis=1), average='macro')\n",
    "        log_message = f'F1 Score: {f1:.2f}'\n",
    "        print(log_message)\n",
    "        logging.info(log_message)\n",
    "        \n",
    "        \n",
    "        auc = roc_auc_score(all_targets, np.max(all_preds, axis=1))\n",
    "        log_message = f'ROC-AUC: {auc:.2f}'\n",
    "        print(log_message)\n",
    "        logging.info(log_message)\n",
    "\n",
    "\n",
    "# 记录总训练时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "log_message = f'Total training time: {total_time:.2f} seconds'\n",
    "print(log_message)\n",
    "logging.info(log_message)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T06:59:40.167473300Z",
     "start_time": "2024-11-11T06:06:25.357578600Z"
    }
   },
   "id": "1ccff31b2aa02523"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToPILImage()\n"
     ]
    }
   ],
   "source": [
    "print(transform)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),  # 随机擦除\n",
    "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),  # 颜色抖动\n",
    "    transforms.Resize([pic_size,pic_size],antialias=False),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T07:02:36.391590500Z",
     "start_time": "2024-11-11T07:02:36.389669700Z"
    }
   },
   "id": "8cd9d86b4964b6d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetWithDilateAttention(\n",
      "  (mdla): MultiDilatelocalAttention(\n",
      "    (qkv): Conv2d(224, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dilate_attention): ModuleList(\n",
      "      (0): DilateAttention(\n",
      "        (unfold): Unfold(kernel_size=3, dilation=2, padding=2, stride=1)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): DilateAttention(\n",
      "        (unfold): Unfold(kernel_size=3, dilation=3, padding=3, stride=1)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (proj): Linear(in_features=224, out_features=224, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (caa): CAA(\n",
      "    (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=3)\n",
      "    (conv1): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(3, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (h_conv): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=3)\n",
      "      )\n",
      "    )\n",
      "    (v_conv): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=3)\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(3, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (act): Sigmoid()\n",
      "  )\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 3, 224, 224])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,\"./DF_CAA_ResNet.pth\")\n",
    "model.eval()\n",
    "img_path=r\"D:\\Datas\\01DWdatas\\6kV西霞线\\照片\\6kV西霞线\\IMG_4090.JPG\"\n",
    "print(model)\n",
    "from PIL import Image, ImageFile\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "import torchvision.transforms as T\n",
    "\n",
    "input=transform(img).cuda()\n",
    "\n",
    "input=torch.unsqueeze(input,0)\n",
    "print(input.shape)\n",
    "layer_name=\"ta\"\n",
    "# 假设你的模型叫model，输入是input\n",
    "layer = model.mdla  # 替换为你想要的层名\n",
    "with torch.no_grad():\n",
    "    output = layer(input)\n",
    "\n",
    "print(type(output))\n",
    "output = output.squeeze(0)\n",
    "print(output.shape)\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.ToPILImage()\n",
    "image = transform(output)\n",
    "\n",
    "# 显示图像\n",
    "image.show()\n",
    "image.save(\"after_ta.jpg\")\n",
    "output=model(input)\n",
    "print(output.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-11T07:02:36.770967300Z"
    }
   },
   "id": "8e576b3caa6c480"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#测试模型\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # Compute individual losses\n",
    "        ce_loss = cross_entropy_loss(output, target)\n",
    "        focal = focal_loss(output, target)\n",
    "        ls_loss = label_smoothing_loss(output, target)\n",
    "        loss = ce_loss +focal +ls_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch}/{num_epochs}, Batch {batch_idx},Total Loss: {loss.item():.4f},Cross Entropy Loss: {ce_loss.item():.4f},Focal Loss: {focal.item():.4f},Label Smoothing Loss: {ls_loss.item():.4f}')\n",
    "\n",
    "    if epoch %10 ==0:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "                # 保存所有预测概率和真实标签\n",
    "                all_preds.extend(probabilities.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "        # 计算准确率\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        # 计算F1分数\n",
    "        f1 = f1_score(all_targets, np.argmax(all_preds, axis=1), average='macro')\n",
    "        print(f'F1 Score: {f1:.2f}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98be5d13d55d0ddd"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.71%\n",
      "F1 Score: 0.83\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # 保存所有预测概率和真实标签\n",
    "        all_preds.extend(probabilities.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(all_targets, np.argmax(all_preds, axis=1), average='macro')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T15:07:17.803971600Z",
     "start_time": "2024-10-04T15:07:04.192239600Z"
    }
   },
   "id": "33208c9eda4fcd7f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetWithDilateAttention(\n",
      "  (mdla): MultiDilatelocalAttention(\n",
      "    (qkv): Conv2d(224, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dilate_attention): ModuleList(\n",
      "      (0): DilateAttention(\n",
      "        (unfold): Unfold(kernel_size=3, dilation=2, padding=2, stride=1)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): DilateAttention(\n",
      "        (unfold): Unfold(kernel_size=3, dilation=3, padding=3, stride=1)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (proj): Linear(in_features=224, out_features=224, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (caa): CAA(\n",
      "    (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=3)\n",
      "    (conv1): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(3, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (h_conv): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=3)\n",
      "      )\n",
      "    )\n",
      "    (v_conv): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=3)\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvModule(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(3, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (act): Sigmoid()\n",
      "  )\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T05:48:40.837160900Z",
     "start_time": "2024-11-11T05:48:40.830652600Z"
    }
   },
   "id": "784c49a7c46118f4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNetWithDilateAttention:\n\tMissing key(s) in state_dict: \"mdla.qkv.weight\", \"mdla.proj.weight\", \"mdla.proj.bias\", \"caa.conv1.block.0.weight\", \"caa.conv1.block.1.weight\", \"caa.conv1.block.1.bias\", \"caa.conv1.block.1.running_mean\", \"caa.conv1.block.1.running_var\", \"caa.h_conv.block.0.weight\", \"caa.h_conv.block.0.bias\", \"caa.v_conv.block.0.weight\", \"caa.v_conv.block.0.bias\", \"caa.conv2.block.0.weight\", \"caa.conv2.block.1.weight\", \"caa.conv2.block.1.bias\", \"caa.conv2.block.1.running_mean\", \"caa.conv2.block.1.running_var\", \"resnet.conv1.weight\", \"resnet.bn1.weight\", \"resnet.bn1.bias\", \"resnet.bn1.running_mean\", \"resnet.bn1.running_var\", \"resnet.layer1.0.conv1.weight\", \"resnet.layer1.0.bn1.weight\", \"resnet.layer1.0.bn1.bias\", \"resnet.layer1.0.bn1.running_mean\", \"resnet.layer1.0.bn1.running_var\", \"resnet.layer1.0.conv2.weight\", \"resnet.layer1.0.bn2.weight\", \"resnet.layer1.0.bn2.bias\", \"resnet.layer1.0.bn2.running_mean\", \"resnet.layer1.0.bn2.running_var\", \"resnet.layer1.0.conv3.weight\", \"resnet.layer1.0.bn3.weight\", \"resnet.layer1.0.bn3.bias\", \"resnet.layer1.0.bn3.running_mean\", \"resnet.layer1.0.bn3.running_var\", \"resnet.layer1.0.downsample.0.weight\", \"resnet.layer1.0.downsample.1.weight\", \"resnet.layer1.0.downsample.1.bias\", \"resnet.layer1.0.downsample.1.running_mean\", \"resnet.layer1.0.downsample.1.running_var\", \"resnet.layer1.1.conv1.weight\", \"resnet.layer1.1.bn1.weight\", \"resnet.layer1.1.bn1.bias\", \"resnet.layer1.1.bn1.running_mean\", \"resnet.layer1.1.bn1.running_var\", \"resnet.layer1.1.conv2.weight\", \"resnet.layer1.1.bn2.weight\", \"resnet.layer1.1.bn2.bias\", \"resnet.layer1.1.bn2.running_mean\", \"resnet.layer1.1.bn2.running_var\", \"resnet.layer1.1.conv3.weight\", \"resnet.layer1.1.bn3.weight\", \"resnet.layer1.1.bn3.bias\", \"resnet.layer1.1.bn3.running_mean\", \"resnet.layer1.1.bn3.running_var\", \"resnet.layer1.2.conv1.weight\", \"resnet.layer1.2.bn1.weight\", \"resnet.layer1.2.bn1.bias\", \"resnet.layer1.2.bn1.running_mean\", \"resnet.layer1.2.bn1.running_var\", \"resnet.layer1.2.conv2.weight\", \"resnet.layer1.2.bn2.weight\", \"resnet.layer1.2.bn2.bias\", \"resnet.layer1.2.bn2.running_mean\", \"resnet.layer1.2.bn2.running_var\", \"resnet.layer1.2.conv3.weight\", \"resnet.layer1.2.bn3.weight\", \"resnet.layer1.2.bn3.bias\", \"resnet.layer1.2.bn3.running_mean\", \"resnet.layer1.2.bn3.running_var\", \"resnet.layer2.0.conv1.weight\", \"resnet.layer2.0.bn1.weight\", \"resnet.layer2.0.bn1.bias\", \"resnet.layer2.0.bn1.running_mean\", \"resnet.layer2.0.bn1.running_var\", \"resnet.layer2.0.conv2.weight\", \"resnet.layer2.0.bn2.weight\", \"resnet.layer2.0.bn2.bias\", \"resnet.layer2.0.bn2.running_mean\", \"resnet.layer2.0.bn2.running_var\", \"resnet.layer2.0.conv3.weight\", \"resnet.layer2.0.bn3.weight\", \"resnet.layer2.0.bn3.bias\", \"resnet.layer2.0.bn3.running_mean\", \"resnet.layer2.0.bn3.running_var\", \"resnet.layer2.0.downsample.0.weight\", \"resnet.layer2.0.downsample.1.weight\", \"resnet.layer2.0.downsample.1.bias\", \"resnet.layer2.0.downsample.1.running_mean\", \"resnet.layer2.0.downsample.1.running_var\", \"resnet.layer2.1.conv1.weight\", \"resnet.layer2.1.bn1.weight\", \"resnet.layer2.1.bn1.bias\", \"resnet.layer2.1.bn1.running_mean\", \"resnet.layer2.1.bn1.running_var\", \"resnet.layer2.1.conv2.weight\", \"resnet.layer2.1.bn2.weight\", \"resnet.layer2.1.bn2.bias\", \"resnet.layer2.1.bn2.running_mean\", \"resnet.layer2.1.bn2.running_var\", \"resnet.layer2.1.conv3.weight\", \"resnet.layer2.1.bn3.weight\", \"resnet.layer2.1.bn3.bias\", \"resnet.layer2.1.bn3.running_mean\", \"resnet.layer2.1.bn3.running_var\", \"resnet.layer2.2.conv1.weight\", \"resnet.layer2.2.bn1.weight\", \"resnet.layer2.2.bn1.bias\", \"resnet.layer2.2.bn1.running_mean\", \"resnet.layer2.2.bn1.running_var\", \"resnet.layer2.2.conv2.weight\", \"resnet.layer2.2.bn2.weight\", \"resnet.layer2.2.bn2.bias\", \"resnet.layer2.2.bn2.running_mean\", \"resnet.layer2.2.bn2.running_var\", \"resnet.layer2.2.conv3.weight\", \"resnet.layer2.2.bn3.weight\", \"resnet.layer2.2.bn3.bias\", \"resnet.layer2.2.bn3.running_mean\", \"resnet.layer2.2.bn3.running_var\", \"resnet.layer2.3.conv1.weight\", \"resnet.layer2.3.bn1.weight\", \"resnet.layer2.3.bn1.bias\", \"resnet.layer2.3.bn1.running_mean\", \"resnet.layer2.3.bn1.running_var\", \"resnet.layer2.3.conv2.weight\", \"resnet.layer2.3.bn2.weight\", \"resnet.layer2.3.bn2.bias\", \"resnet.layer2.3.bn2.running_mean\", \"resnet.layer2.3.bn2.running_var\", \"resnet.layer2.3.conv3.weight\", \"resnet.layer2.3.bn3.weight\", \"resnet.layer2.3.bn3.bias\", \"resnet.layer2.3.bn3.running_mean\", \"resnet.layer2.3.bn3.running_var\", \"resnet.layer3.0.conv1.weight\", \"resnet.layer3.0.bn1.weight\", \"resnet.layer3.0.bn1.bias\", \"resnet.layer3.0.bn1.running_mean\", \"resnet.layer3.0.bn1.running_var\", \"resnet.layer3.0.conv2.weight\", \"resnet.layer3.0.bn2.weight\", \"resnet.layer3.0.bn2.bias\", \"resnet.layer3.0.bn2.running_mean\", \"resnet.layer3.0.bn2.running_var\", \"resnet.layer3.0.conv3.weight\", \"resnet.layer3.0.bn3.weight\", \"resnet.layer3.0.bn3.bias\", \"resnet.layer3.0.bn3.running_mean\", \"resnet.layer3.0.bn3.running_var\", \"resnet.layer3.0.downsample.0.weight\", \"resnet.layer3.0.downsample.1.weight\", \"resnet.layer3.0.downsample.1.bias\", \"resnet.layer3.0.downsample.1.running_mean\", \"resnet.layer3.0.downsample.1.running_var\", \"resnet.layer3.1.conv1.weight\", \"resnet.layer3.1.bn1.weight\", \"resnet.layer3.1.bn1.bias\", \"resnet.layer3.1.bn1.running_mean\", \"resnet.layer3.1.bn1.running_var\", \"resnet.layer3.1.conv2.weight\", \"resnet.layer3.1.bn2.weight\", \"resnet.layer3.1.bn2.bias\", \"resnet.layer3.1.bn2.running_mean\", \"resnet.layer3.1.bn2.running_var\", \"resnet.layer3.1.conv3.weight\", \"resnet.layer3.1.bn3.weight\", \"resnet.layer3.1.bn3.bias\", \"resnet.layer3.1.bn3.running_mean\", \"resnet.layer3.1.bn3.running_var\", \"resnet.layer3.2.conv1.weight\", \"resnet.layer3.2.bn1.weight\", \"resnet.layer3.2.bn1.bias\", \"resnet.layer3.2.bn1.running_mean\", \"resnet.layer3.2.bn1.running_var\", \"resnet.layer3.2.conv2.weight\", \"resnet.layer3.2.bn2.weight\", \"resnet.layer3.2.bn2.bias\", \"resnet.layer3.2.bn2.running_mean\", \"resnet.layer3.2.bn2.running_var\", \"resnet.layer3.2.conv3.weight\", \"resnet.layer3.2.bn3.weight\", \"resnet.layer3.2.bn3.bias\", \"resnet.layer3.2.bn3.running_mean\", \"resnet.layer3.2.bn3.running_var\", \"resnet.layer3.3.conv1.weight\", \"resnet.layer3.3.bn1.weight\", \"resnet.layer3.3.bn1.bias\", \"resnet.layer3.3.bn1.running_mean\", \"resnet.layer3.3.bn1.running_var\", \"resnet.layer3.3.conv2.weight\", \"resnet.layer3.3.bn2.weight\", \"resnet.layer3.3.bn2.bias\", \"resnet.layer3.3.bn2.running_mean\", \"resnet.layer3.3.bn2.running_var\", \"resnet.layer3.3.conv3.weight\", \"resnet.layer3.3.bn3.weight\", \"resnet.layer3.3.bn3.bias\", \"resnet.layer3.3.bn3.running_mean\", \"resnet.layer3.3.bn3.running_var\", \"resnet.layer3.4.conv1.weight\", \"resnet.layer3.4.bn1.weight\", \"resnet.layer3.4.bn1.bias\", \"resnet.layer3.4.bn1.running_mean\", \"resnet.layer3.4.bn1.running_var\", \"resnet.layer3.4.conv2.weight\", \"resnet.layer3.4.bn2.weight\", \"resnet.layer3.4.bn2.bias\", \"resnet.layer3.4.bn2.running_mean\", \"resnet.layer3.4.bn2.running_var\", \"resnet.layer3.4.conv3.weight\", \"resnet.layer3.4.bn3.weight\", \"resnet.layer3.4.bn3.bias\", \"resnet.layer3.4.bn3.running_mean\", \"resnet.layer3.4.bn3.running_var\", \"resnet.layer3.5.conv1.weight\", \"resnet.layer3.5.bn1.weight\", \"resnet.layer3.5.bn1.bias\", \"resnet.layer3.5.bn1.running_mean\", \"resnet.layer3.5.bn1.running_var\", \"resnet.layer3.5.conv2.weight\", \"resnet.layer3.5.bn2.weight\", \"resnet.layer3.5.bn2.bias\", \"resnet.layer3.5.bn2.running_mean\", \"resnet.layer3.5.bn2.running_var\", \"resnet.layer3.5.conv3.weight\", \"resnet.layer3.5.bn3.weight\", \"resnet.layer3.5.bn3.bias\", \"resnet.layer3.5.bn3.running_mean\", \"resnet.layer3.5.bn3.running_var\", \"resnet.layer4.0.conv1.weight\", \"resnet.layer4.0.bn1.weight\", \"resnet.layer4.0.bn1.bias\", \"resnet.layer4.0.bn1.running_mean\", \"resnet.layer4.0.bn1.running_var\", \"resnet.layer4.0.conv2.weight\", \"resnet.layer4.0.bn2.weight\", \"resnet.layer4.0.bn2.bias\", \"resnet.layer4.0.bn2.running_mean\", \"resnet.layer4.0.bn2.running_var\", \"resnet.layer4.0.conv3.weight\", \"resnet.layer4.0.bn3.weight\", \"resnet.layer4.0.bn3.bias\", \"resnet.layer4.0.bn3.running_mean\", \"resnet.layer4.0.bn3.running_var\", \"resnet.layer4.0.downsample.0.weight\", \"resnet.layer4.0.downsample.1.weight\", \"resnet.layer4.0.downsample.1.bias\", \"resnet.layer4.0.downsample.1.running_mean\", \"resnet.layer4.0.downsample.1.running_var\", \"resnet.layer4.1.conv1.weight\", \"resnet.layer4.1.bn1.weight\", \"resnet.layer4.1.bn1.bias\", \"resnet.layer4.1.bn1.running_mean\", \"resnet.layer4.1.bn1.running_var\", \"resnet.layer4.1.conv2.weight\", \"resnet.layer4.1.bn2.weight\", \"resnet.layer4.1.bn2.bias\", \"resnet.layer4.1.bn2.running_mean\", \"resnet.layer4.1.bn2.running_var\", \"resnet.layer4.1.conv3.weight\", \"resnet.layer4.1.bn3.weight\", \"resnet.layer4.1.bn3.bias\", \"resnet.layer4.1.bn3.running_mean\", \"resnet.layer4.1.bn3.running_var\", \"resnet.layer4.2.conv1.weight\", \"resnet.layer4.2.bn1.weight\", \"resnet.layer4.2.bn1.bias\", \"resnet.layer4.2.bn1.running_mean\", \"resnet.layer4.2.bn1.running_var\", \"resnet.layer4.2.conv2.weight\", \"resnet.layer4.2.bn2.weight\", \"resnet.layer4.2.bn2.bias\", \"resnet.layer4.2.bn2.running_mean\", \"resnet.layer4.2.bn2.running_var\", \"resnet.layer4.2.conv3.weight\", \"resnet.layer4.2.bn3.weight\", \"resnet.layer4.2.bn3.bias\", \"resnet.layer4.2.bn3.running_mean\", \"resnet.layer4.2.bn3.running_var\", \"resnet.fc.weight\", \"resnet.fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.num_batches_tracked\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.num_batches_tracked\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer1.2.bn3.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.bn3.num_batches_tracked\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.1.bn3.num_batches_tracked\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.2.bn3.num_batches_tracked\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.num_batches_tracked\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.num_batches_tracked\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer2.3.bn3.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.num_batches_tracked\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.num_batches_tracked\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.num_batches_tracked\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.num_batches_tracked\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.num_batches_tracked\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.num_batches_tracked\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.num_batches_tracked\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.num_batches_tracked\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.num_batches_tracked\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.num_batches_tracked\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.num_batches_tracked\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.num_batches_tracked\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.num_batches_tracked\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.num_batches_tracked\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.num_batches_tracked\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.num_batches_tracked\", \"fc.weight\", \"fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m DF_CAA_ResNet\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mgaoge\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mDesktop\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mGHOME\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m01projs\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m03mycodes\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtmp\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m12杆塔分类\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmodel.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m DF_CAA_ResNet\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mload(DF_CAA_ResNet)\n\u001B[1;32m----> 3\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(DF_CAA_ResNet)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m      5\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict)\u001B[0m\n\u001B[0;32m   2036\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2037\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2038\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[0;32m   2040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2041\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2042\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[0;32m   2043\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for ResNetWithDilateAttention:\n\tMissing key(s) in state_dict: \"mdla.qkv.weight\", \"mdla.proj.weight\", \"mdla.proj.bias\", \"caa.conv1.block.0.weight\", \"caa.conv1.block.1.weight\", \"caa.conv1.block.1.bias\", \"caa.conv1.block.1.running_mean\", \"caa.conv1.block.1.running_var\", \"caa.h_conv.block.0.weight\", \"caa.h_conv.block.0.bias\", \"caa.v_conv.block.0.weight\", \"caa.v_conv.block.0.bias\", \"caa.conv2.block.0.weight\", \"caa.conv2.block.1.weight\", \"caa.conv2.block.1.bias\", \"caa.conv2.block.1.running_mean\", \"caa.conv2.block.1.running_var\", \"resnet.conv1.weight\", \"resnet.bn1.weight\", \"resnet.bn1.bias\", \"resnet.bn1.running_mean\", \"resnet.bn1.running_var\", \"resnet.layer1.0.conv1.weight\", \"resnet.layer1.0.bn1.weight\", \"resnet.layer1.0.bn1.bias\", \"resnet.layer1.0.bn1.running_mean\", \"resnet.layer1.0.bn1.running_var\", \"resnet.layer1.0.conv2.weight\", \"resnet.layer1.0.bn2.weight\", \"resnet.layer1.0.bn2.bias\", \"resnet.layer1.0.bn2.running_mean\", \"resnet.layer1.0.bn2.running_var\", \"resnet.layer1.0.conv3.weight\", \"resnet.layer1.0.bn3.weight\", \"resnet.layer1.0.bn3.bias\", \"resnet.layer1.0.bn3.running_mean\", \"resnet.layer1.0.bn3.running_var\", \"resnet.layer1.0.downsample.0.weight\", \"resnet.layer1.0.downsample.1.weight\", \"resnet.layer1.0.downsample.1.bias\", \"resnet.layer1.0.downsample.1.running_mean\", \"resnet.layer1.0.downsample.1.running_var\", \"resnet.layer1.1.conv1.weight\", \"resnet.layer1.1.bn1.weight\", \"resnet.layer1.1.bn1.bias\", \"resnet.layer1.1.bn1.running_mean\", \"resnet.layer1.1.bn1.running_var\", \"resnet.layer1.1.conv2.weight\", \"resnet.layer1.1.bn2.weight\", \"resnet.layer1.1.bn2.bias\", \"resnet.layer1.1.bn2.running_mean\", \"resnet.layer1.1.bn2.running_var\", \"resnet.layer1.1.conv3.weight\", \"resnet.layer1.1.bn3.weight\", \"resnet.layer1.1.bn3.bias\", \"resnet.layer1.1.bn3.running_mean\", \"resnet.layer1.1.bn3.running_var\", \"resnet.layer1.2.conv1.weight\", \"resnet.layer1.2.bn1.weight\", \"resnet.layer1.2.bn1.bias\", \"resnet.layer1.2.bn1.running_mean\", \"resnet.layer1.2.bn1.running_var\", \"resnet.layer1.2.conv2.weight\", \"resnet.layer1.2.bn2.weight\", \"resnet.layer1.2.bn2.bias\", \"resnet.layer1.2.bn2.running_mean\", \"resnet.layer1.2.bn2.running_var\", \"resnet.layer1.2.conv3.weight\", \"resnet.layer1.2.bn3.weight\", \"resnet.layer1.2.bn3.bias\", \"resnet.layer1.2.bn3.running_mean\", \"resnet.layer1.2.bn3.running_var\", \"resnet.layer2.0.conv1.weight\", \"resnet.layer2.0.bn1.weight\", \"resnet.layer2.0.bn1.bias\", \"resnet.layer2.0.bn1.running_mean\", \"resnet.layer2.0.bn1.running_var\", \"resnet.layer2.0.conv2.weight\", \"resnet.layer2.0.bn2.weight\", \"resnet.layer2.0.bn2.bias\", \"resnet.layer2.0.bn2.running_mean\", \"resnet.layer2.0.bn2.running_var\", \"resnet.layer2.0.conv3.weight\", \"resnet.layer2.0.bn3.weight\", \"resnet.layer2.0.bn3.bias\", \"resnet.layer2.0.bn3.running_mean\", \"resnet.layer2.0.bn3.running_var\", \"resnet.layer2.0.downsample.0.weight\", \"resnet.layer2.0.downsample.1.weight\", \"resnet.layer2.0.downsample.1.bias\", \"resnet.layer2.0.downsample.1.running_mean\", \"resnet.layer2.0.downsample.1.running_var\", \"resnet.layer2.1.conv1.weight\", \"resnet.layer2.1.bn1.weight\", \"resnet.layer2.1.bn1.bias\", \"resnet.layer2.1.bn1.running_mean\", \"resnet.layer2.1.bn1.running_var\", \"resnet.layer2.1.conv2.weight\", \"resnet.layer2.1.bn2.weight\", \"resnet.layer2.1.bn2.bias\", \"resnet.layer2.1.bn2.running_mean\", \"resnet.layer2.1.bn2.running_var\", \"resnet.layer2.1.conv3.weight\", \"resnet.layer2.1.bn3.weight\", \"resnet.layer2.1.bn3.bias\", \"resnet.layer2.1.bn3.running_mean\", \"resnet.layer2.1.bn3.running_var\", \"resnet.layer2.2.conv1.weight\", \"resnet.layer2.2.bn1.weight\", \"resnet.layer2.2.bn1.bias\", \"resnet.layer2.2.bn1.running_mean\", \"resnet.layer2.2.bn1.running_var\", \"resnet.layer2.2.conv2.weight\", \"resnet.layer2.2.bn2.weight\", \"resnet.layer2.2.bn2.bias\", \"resnet.layer2.2.bn2.running_mean\", \"resnet.layer2.2.bn2.running_var\", \"resnet.layer2.2.conv3.weight\", \"resnet.layer2.2.bn3.weight\", \"resnet.layer2.2.bn3.bias\", \"resnet.layer2.2.bn3.running_mean\", \"resnet.layer2.2.bn3.running_var\", \"resnet.layer2.3.conv1.weight\", \"resnet.layer2.3.bn1.weight\", \"resnet.layer2.3.bn1.bias\", \"resnet.layer2.3.bn1.running_mean\", \"resnet.layer2.3.bn1.running_var\", \"resnet.layer2.3.conv2.weight\", \"resnet.layer2.3.bn2.weight\", \"resnet.layer2.3.bn2.bias\", \"resnet.layer2.3.bn2.running_mean\", \"resnet.layer2.3.bn2.running_var\", \"resnet.layer2.3.conv3.weight\", \"resnet.layer2.3.bn3.weight\", \"resnet.layer2.3.bn3.bias\", \"resnet.layer2.3.bn3.running_mean\", \"resnet.layer2.3.bn3.running_var\", \"resnet.layer3.0.conv1.weight\", \"resnet.layer3.0.bn1.weight\", \"resnet.layer3.0.bn1.bias\", \"resnet.layer3.0.bn1.running_mean\", \"resnet.layer3.0.bn1.running_var\", \"resnet.layer3.0.conv2.weight\", \"resnet.layer3.0.bn2.weight\", \"resnet.layer3.0.bn2.bias\", \"resnet.layer3.0.bn2.running_mean\", \"resnet.layer3.0.bn2.running_var\", \"resnet.layer3.0.conv3.weight\", \"resnet.layer3.0.bn3.weight\", \"resnet.layer3.0.bn3.bias\", \"resnet.layer3.0.bn3.running_mean\", \"resnet.layer3.0.bn3.running_var\", \"resnet.layer3.0.downsample.0.weight\", \"resnet.layer3.0.downsample.1.weight\", \"resnet.layer3.0.downsample.1.bias\", \"resnet.layer3.0.downsample.1.running_mean\", \"resnet.layer3.0.downsample.1.running_var\", \"resnet.layer3.1.conv1.weight\", \"resnet.layer3.1.bn1.weight\", \"resnet.layer3.1.bn1.bias\", \"resnet.layer3.1.bn1.running_mean\", \"resnet.layer3.1.bn1.running_var\", \"resnet.layer3.1.conv2.weight\", \"resnet.layer3.1.bn2.weight\", \"resnet.layer3.1.bn2.bias\", \"resnet.layer3.1.bn2.running_mean\", \"resnet.layer3.1.bn2.running_var\", \"resnet.layer3.1.conv3.weight\", \"resnet.layer3.1.bn3.weight\", \"resnet.layer3.1.bn3.bias\", \"resnet.layer3.1.bn3.running_mean\", \"resnet.layer3.1.bn3.running_var\", \"resnet.layer3.2.conv1.weight\", \"resnet.layer3.2.bn1.weight\", \"resnet.layer3.2.bn1.bias\", \"resnet.layer3.2.bn1.running_mean\", \"resnet.layer3.2.bn1.running_var\", \"resnet.layer3.2.conv2.weight\", \"resnet.layer3.2.bn2.weight\", \"resnet.layer3.2.bn2.bias\", \"resnet.layer3.2.bn2.running_mean\", \"resnet.layer3.2.bn2.running_var\", \"resnet.layer3.2.conv3.weight\", \"resnet.layer3.2.bn3.weight\", \"resnet.layer3.2.bn3.bias\", \"resnet.layer3.2.bn3.running_mean\", \"resnet.layer3.2.bn3.running_var\", \"resnet.layer3.3.conv1.weight\", \"resnet.layer3.3.bn1.weight\", \"resnet.layer3.3.bn1.bias\", \"resnet.layer3.3.bn1.running_mean\", \"resnet.layer3.3.bn1.running_var\", \"resnet.layer3.3.conv2.weight\", \"resnet.layer3.3.bn2.weight\", \"resnet.layer3.3.bn2.bias\", \"resnet.layer3.3.bn2.running_mean\", \"resnet.layer3.3.bn2.running_var\", \"resnet.layer3.3.conv3.weight\", \"resnet.layer3.3.bn3.weight\", \"resnet.layer3.3.bn3.bias\", \"resnet.layer3.3.bn3.running_mean\", \"resnet.layer3.3.bn3.running_var\", \"resnet.layer3.4.conv1.weight\", \"resnet.layer3.4.bn1.weight\", \"resnet.layer3.4.bn1.bias\", \"resnet.layer3.4.bn1.running_mean\", \"resnet.layer3.4.bn1.running_var\", \"resnet.layer3.4.conv2.weight\", \"resnet.layer3.4.bn2.weight\", \"resnet.layer3.4.bn2.bias\", \"resnet.layer3.4.bn2.running_mean\", \"resnet.layer3.4.bn2.running_var\", \"resnet.layer3.4.conv3.weight\", \"resnet.layer3.4.bn3.weight\", \"resnet.layer3.4.bn3.bias\", \"resnet.layer3.4.bn3.running_mean\", \"resnet.layer3.4.bn3.running_var\", \"resnet.layer3.5.conv1.weight\", \"resnet.layer3.5.bn1.weight\", \"resnet.layer3.5.bn1.bias\", \"resnet.layer3.5.bn1.running_mean\", \"resnet.layer3.5.bn1.running_var\", \"resnet.layer3.5.conv2.weight\", \"resnet.layer3.5.bn2.weight\", \"resnet.layer3.5.bn2.bias\", \"resnet.layer3.5.bn2.running_mean\", \"resnet.layer3.5.bn2.running_var\", \"resnet.layer3.5.conv3.weight\", \"resnet.layer3.5.bn3.weight\", \"resnet.layer3.5.bn3.bias\", \"resnet.layer3.5.bn3.running_mean\", \"resnet.layer3.5.bn3.running_var\", \"resnet.layer4.0.conv1.weight\", \"resnet.layer4.0.bn1.weight\", \"resnet.layer4.0.bn1.bias\", \"resnet.layer4.0.bn1.running_mean\", \"resnet.layer4.0.bn1.running_var\", \"resnet.layer4.0.conv2.weight\", \"resnet.layer4.0.bn2.weight\", \"resnet.layer4.0.bn2.bias\", \"resnet.layer4.0.bn2.running_mean\", \"resnet.layer4.0.bn2.running_var\", \"resnet.layer4.0.conv3.weight\", \"resnet.layer4.0.bn3.weight\", \"resnet.layer4.0.bn3.bias\", \"resnet.layer4.0.bn3.running_mean\", \"resnet.layer4.0.bn3.running_var\", \"resnet.layer4.0.downsample.0.weight\", \"resnet.layer4.0.downsample.1.weight\", \"resnet.layer4.0.downsample.1.bias\", \"resnet.layer4.0.downsample.1.running_mean\", \"resnet.layer4.0.downsample.1.running_var\", \"resnet.layer4.1.conv1.weight\", \"resnet.layer4.1.bn1.weight\", \"resnet.layer4.1.bn1.bias\", \"resnet.layer4.1.bn1.running_mean\", \"resnet.layer4.1.bn1.running_var\", \"resnet.layer4.1.conv2.weight\", \"resnet.layer4.1.bn2.weight\", \"resnet.layer4.1.bn2.bias\", \"resnet.layer4.1.bn2.running_mean\", \"resnet.layer4.1.bn2.running_var\", \"resnet.layer4.1.conv3.weight\", \"resnet.layer4.1.bn3.weight\", \"resnet.layer4.1.bn3.bias\", \"resnet.layer4.1.bn3.running_mean\", \"resnet.layer4.1.bn3.running_var\", \"resnet.layer4.2.conv1.weight\", \"resnet.layer4.2.bn1.weight\", \"resnet.layer4.2.bn1.bias\", \"resnet.layer4.2.bn1.running_mean\", \"resnet.layer4.2.bn1.running_var\", \"resnet.layer4.2.conv2.weight\", \"resnet.layer4.2.bn2.weight\", \"resnet.layer4.2.bn2.bias\", \"resnet.layer4.2.bn2.running_mean\", \"resnet.layer4.2.bn2.running_var\", \"resnet.layer4.2.conv3.weight\", \"resnet.layer4.2.bn3.weight\", \"resnet.layer4.2.bn3.bias\", \"resnet.layer4.2.bn3.running_mean\", \"resnet.layer4.2.bn3.running_var\", \"resnet.fc.weight\", \"resnet.fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.num_batches_tracked\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.num_batches_tracked\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.num_batches_tracked\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer1.2.bn3.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.bn3.num_batches_tracked\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.1.bn3.num_batches_tracked\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.2.bn3.num_batches_tracked\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.num_batches_tracked\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.num_batches_tracked\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer2.3.bn3.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.num_batches_tracked\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.num_batches_tracked\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.num_batches_tracked\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.num_batches_tracked\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.num_batches_tracked\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.num_batches_tracked\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.num_batches_tracked\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.num_batches_tracked\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.num_batches_tracked\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.num_batches_tracked\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.num_batches_tracked\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.num_batches_tracked\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.num_batches_tracked\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.num_batches_tracked\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.num_batches_tracked\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.num_batches_tracked\", \"fc.weight\", \"fc.bias\". "
     ]
    }
   ],
   "source": [
    "DF_CAA_ResNet=r\"C:\\Users\\gaoge\\Desktop\\GHOME\\01projs\\03mycodes\\tmp\\12杆塔分类\\model.pth\"\n",
    "DF_CAA_ResNet=torch.load(DF_CAA_ResNet)\n",
    "model.load_state_dict(DF_CAA_ResNet)\n",
    "with torch.no_grad():\n",
    "    model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T05:53:29.530511600Z",
     "start_time": "2024-11-11T05:53:29.240517Z"
    }
   },
   "id": "831cdfcfa71751d7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./model.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1994\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict)\u001B[0m\n\u001B[0;32m   1971\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001B[39;00m\n\u001B[0;32m   1972\u001B[0m \u001B[38;5;124;03mthis module and its descendants. If :attr:`strict` is ``True``, then\u001B[39;00m\n\u001B[0;32m   1973\u001B[0m \u001B[38;5;124;03mthe keys of :attr:`state_dict` must exactly match the keys returned\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1991\u001B[0m \u001B[38;5;124;03m    ``RuntimeError``.\u001B[39;00m\n\u001B[0;32m   1992\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1993\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(state_dict, Mapping):\n\u001B[1;32m-> 1994\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected state_dict to be dict-like, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(state_dict)))\n\u001B[0;32m   1996\u001B[0m missing_keys: List[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1997\u001B[0m unexpected_keys: List[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mTypeError\u001B[0m: Expected state_dict to be dict-like, got <class 'str'>."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = r\"C:\\Users\\gaoge\\Desktop\\GHOME\\01projs\\03mycodes\\tmp\\12杆塔分类\\MyGTData\\train\\直线杆\\IMG_1498.JPG\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Define the image transformations (resize, normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),  # 随机擦除\n",
    "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),  # 颜色抖动\n",
    "    transforms.Resize([pic_size,pic_size],antialias=False),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Apply transformations and add batch dimension\n",
    "input_tensor = transform(image).unsqueeze(0).cuda()\n",
    "\n",
    "# Load your model\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Initialize GradCAM with the target layer (e.g., last conv layer in ResNet)\n",
    "cam_extractor = GradCAM(model, target_layer=\"resnet.layer4\")  # Change the layer to the appropriate one\n",
    "\n",
    "# Forward pass to get the model's output\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Generate the CAM for the target class (if you know the class index, use it; otherwise, pick the predicted class)\n",
    "activation_map = cam_extractor(output.squeeze(0).argmax().item(), output)\n",
    "tmp=transforms.ToPILImage()(activation_map[0])\n",
    "# Visualize the heatmap\n",
    "# Convert the image to a format suitable for overlay\n",
    "rgb_img = image  # Convert back to PIL for visualization\n",
    "\n",
    "# Overlay the heatmap on the original image\n",
    "result = overlay_mask(rgb_img, tmp, alpha=0.8)\n",
    "\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-11T05:49:21.284972500Z"
    }
   },
   "id": "66709723a63b5757"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape:torch.Size([1, 2048, 7, 7])\n",
      "feature shape:torch.Size([1, 2048, 7, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaoge\\AppData\\Local\\Temp\\ipykernel_26300\\2355520587.py:98: UserWarning: results\\IMG_1510-tmp-gb.jpg is a low contrast image\n",
      "  io.imsave(os.path.join(output_dir, '{}-{}-{}.jpg'.format(prefix, 'tmp', key)), image)\n",
      "C:\\Users\\gaoge\\AppData\\Local\\Temp\\ipykernel_26300\\2355520587.py:98: UserWarning: results\\IMG_1510-tmp-cam_gb.jpg is a low contrast image\n",
      "  io.imsave(os.path.join(output_dir, '{}-{}-{}.jpg'.format(prefix, 'tmp', key)), image)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 2019/8/4 上午9:53\n",
    "\n",
    "@author: mick.yi\n",
    "\n",
    "入口类\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage import io\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "from interpretability.grad_cam import GradCAM, GradCamPlusPlus\n",
    "from interpretability.guided_back_propagation import GuidedBackPropagation\n",
    "\n",
    "\n",
    "def get_last_conv_name(net):\n",
    "    \"\"\"\n",
    "    获取网络的最后一个卷积层的名字\n",
    "    :param net:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layer_name = None\n",
    "    for name, m in net.named_modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            layer_name = name\n",
    "    return layer_name\n",
    "\n",
    "\n",
    "def prepare_input(image):\n",
    "    image = image.copy()\n",
    "\n",
    "    # 归一化\n",
    "    means = np.array([0.485, 0.456, 0.406])\n",
    "    stds = np.array([0.229, 0.224, 0.225])\n",
    "    image -= means\n",
    "    image /= stds\n",
    "\n",
    "    image = np.ascontiguousarray(np.transpose(image, (2, 0, 1)))  # channel first\n",
    "    image = image[np.newaxis, ...]  # 增加batch维\n",
    "\n",
    "    return torch.tensor(image, requires_grad=True)\n",
    "\n",
    "\n",
    "def gen_cam(image, mask):\n",
    "    \"\"\"\n",
    "    生成CAM图\n",
    "    :param image: [H,W,C],原始图像\n",
    "    :param mask: [H,W],范围0~1\n",
    "    :return: tuple(cam,heatmap)\n",
    "    \"\"\"\n",
    "    # mask转为heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    heatmap = heatmap[..., ::-1]  # gbr to rgb\n",
    "\n",
    "    # 合并heatmap到原始图像\n",
    "    cam = heatmap + np.float32(image)\n",
    "    return norm_image(cam), (heatmap * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def norm_image(image):\n",
    "    \"\"\"\n",
    "    标准化图像\n",
    "    :param image: [H,W,C]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    image -= np.max(np.min(image), 0)\n",
    "    image /= np.max(image)\n",
    "    image *= 255.\n",
    "    return np.uint8(image)\n",
    "\n",
    "\n",
    "def gen_gb(grad):\n",
    "    \"\"\"\n",
    "    生guided back propagation 输入图像的梯度\n",
    "    :param grad: tensor,[3,H,W]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 标准化\n",
    "    grad = grad.data.numpy()\n",
    "    gb = np.transpose(grad, (1, 2, 0))\n",
    "    return gb\n",
    "\n",
    "\n",
    "def save_image(image_dicts, input_image_name, network, output_dir):\n",
    "    prefix = os.path.splitext(input_image_name)[0]\n",
    "    for key, image in image_dicts.items():\n",
    "        io.imsave(os.path.join(output_dir, '{}-{}-{}.jpg'.format(prefix, 'tmp', key)), image)\n",
    "\n",
    "\n",
    "image_path=r\"C:\\Users\\gaoge\\Desktop\\GHOME\\01projs\\03mycodes\\tmp\\12杆塔分类\\MyGTData\\train\\耐张杆\\IMG_1510.JPG\"\n",
    "network=model\n",
    "weight_path=None\n",
    "layer_name='resnet.layer4'\n",
    "class_id=None\n",
    "output_dir=\"results\"\n",
    "# 输入\n",
    "img = io.imread(image_path)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "inputs = prepare_input(img)\n",
    "# 输出图像\n",
    "image_dict = {}\n",
    "# 网络\n",
    "net = network.to('cpu')\n",
    "# Grad-CAM\n",
    "layer_name = get_last_conv_name(net) if layer_name is None else layer_name\n",
    "grad_cam = GradCAM(net, layer_name)\n",
    "mask = grad_cam(inputs, class_id)  # cam mask\n",
    "image_dict['cam'], image_dict['heatmap'] = gen_cam(img, mask)\n",
    "grad_cam.remove_handlers()\n",
    "# Grad-CAM++\n",
    "grad_cam_plus_plus = GradCamPlusPlus(net, layer_name)\n",
    "mask_plus_plus = grad_cam_plus_plus(inputs, class_id)  # cam mask\n",
    "image_dict['cam++'], image_dict['heatmap++'] = gen_cam(img, mask_plus_plus)\n",
    "grad_cam_plus_plus.remove_handlers()\n",
    "\n",
    "# GuidedBackPropagation\n",
    "gbp = GuidedBackPropagation(net)\n",
    "inputs.grad.zero_()  # 梯度置零\n",
    "grad = gbp(inputs)\n",
    "\n",
    "gb = gen_gb(grad)\n",
    "image_dict['gb'] = norm_image(gb)\n",
    "# 生成Guided Grad-CAM\n",
    "cam_gb = gb * mask[..., np.newaxis]\n",
    "image_dict['cam_gb'] = norm_image(cam_gb)\n",
    "\n",
    "save_image(image_dict, os.path.basename(image_path), network, output_dir)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T15:15:36.245903100Z",
     "start_time": "2024-10-04T15:15:34.832439900Z"
    }
   },
   "id": "4d394f242296120"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b2c3cbc5f3feb1c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
